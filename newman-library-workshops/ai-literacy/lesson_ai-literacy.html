<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>AI Literacy Workshop</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="lesson_ai-literacy_files/libs/clipboard/clipboard.min.js"></script>
<script src="lesson_ai-literacy_files/libs/quarto-html/quarto.js"></script>
<script src="lesson_ai-literacy_files/libs/quarto-html/popper.min.js"></script>
<script src="lesson_ai-literacy_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="lesson_ai-literacy_files/libs/quarto-html/anchor.min.js"></script>
<link href="lesson_ai-literacy_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="lesson_ai-literacy_files/libs/quarto-html/quarto-syntax-highlighting-07ba0ad10f5680c660e360ac31d2f3b6.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="lesson_ai-literacy_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="lesson_ai-literacy_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="lesson_ai-literacy_files/libs/bootstrap/bootstrap-fe6593aca1dacbc749dc3d2ba78c8639.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


<link rel="stylesheet" href="custom.css">
</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">AI Literacy Workshop</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="table-of-contents" class="level2">
<h2 class="anchored" data-anchor-id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#ai-literacy-workshop">AI Literacy Workshop</a></li>
<li><a href="#generative-ai">Generative AI</a></li>
<li><a href="#large-language-models-llm">Large Language Models (LLM)</a></li>
<li><a href="#retrieval-augmented-generation">Retrieval Augmented Generation (RAG)</a></li>
<li><a href="#ai-search">AI Search</a></li>
<li><a href="#glossary">Glossary</a></li>
</ul>
<hr>
</section>
<section id="generative-ai" class="level2">
<h2 class="anchored" data-anchor-id="generative-ai">Generative AI</h2>
<p>Generative AI refers to tools that can create new content - text, images, video, code, even music - based on written or spoken prompts. These systems are designed to recognize patterns in data and generate outputs that look and sound like human-created work.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/gen-ai/generative-ai-boxes.png" class="img-fluid figure-img"></p>
<figcaption>generative-ai</figcaption>
</figure>
</div>
<p>This gives students and researchers remarkable power: you can brainstorm ideas, visualize complex concepts, or rehearse how to explain them. But be cautious: just because AI can generate content does not mean that content is accurate, verified, or most importantly: appropriate to cite as an authority. Always consult your instructor or course syllabus to determine whether using generative AI is permitted in your coursework.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Tool</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://www.microsoft.com/en-us/microsoft-copilot">Microsoft Copilot</a></td>
<td>Microsoft Copilot is an AI assistant built into Microsoft 365. Copilot functions as a traditional AI-powered chatbot enabling it to summarize, analyze, and generate text and code. Copilot is the default generative AI tool at Baruch College because the CUNY-secure deployment ensures that data stays within the protected institutional environment and is not shared externally. While Copilot is widely available to the public, students and faculty should access the data-secure version through Microsoft Office 365 on the web or local installation.</td>
</tr>
<tr class="even">
<td><a href="https://chat.openai.com/">OpenAI ChatGPT</a></td>
<td>ChatGPT, powered by OpenAI’s GPT models, is widely regarded as the industry standard for conversational AI. Known for its versatility and fluency, it is a powerful general-purpose model that can generate, summarize, and analyze text across a wide range of domains.</td>
</tr>
<tr class="odd">
<td><a href="https://gemini.google.com/">Google Gemini</a></td>
<td>Gemini is Google’s multimodal model, designed to natively understand and work with text, images, video, and audio. It represents Google’s flagship LLM platform and integrates tightly with other Google products and services.</td>
</tr>
<tr class="even">
<td><a href="https://www.anthropic.com/claude">Anthropic Claude</a></td>
<td>Claude, developed by Anthropic, emphasizes safety and ethical alignment through an approach known as “Constitutional AI.” It is designed to reduce harmful outputs while still being a capable and versatile conversational model.</td>
</tr>
<tr class="odd">
<td><a href="https://ai.meta.com/llama/">Meta Llama 3</a></td>
<td>Llama 3 is Meta’s open-source family of Large Language Models, freely available for developers and researchers. It is widely used in academic and industry projects, offering strong performance with flexible licensing compared to commercial models.</td>
</tr>
<tr class="even">
<td><a href="https://mistral.ai/">Mistral</a></td>
<td>Mistral AI is a European startup developing powerful open-source and commercial LLMs, emphasizing efficiency and smaller models that run well on limited hardware.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="large-language-models-llm" class="level2">
<h2 class="anchored" data-anchor-id="large-language-models-llm">Large Language Models (LLM)</h2>
<p>Artificial Intelligence is undoubtedly reshaping how we access, evaluate, and create information. From chatbots to research assistants, AI tools are increasingly part of everyday academic life. This teaching note focuses on a crucial piece of AI Literacy: understanding how large language models like ChatGPT, Gemini, and Claude work - and how they influence the way students and researchers discover, retrieve, and interact with information.</p>
<p>Although this note is focused on “AI Literacy,” the key part of understanding modern AI for information retrieval is maintaining a strong command of text-based Generative AI tools. This primarily means understanding the Large Language Model (LLM) with a focus on the inner-workings of popular chatbots powered by LLMs like OpenAI’s ChatGPT and Google’s Gemini.</p>
<p>The large language models that power popular technologies like ChatGPT and Gemini also drive many other AI tools discussed in this guide. These include specialized applications such as research assistants (e.g., Elicit) and consumer-facing Retrieval-Augmented Generation (RAG) tools (e.g., Google’s NotebookLM).</p>
<p>There are no doubt noteworthy developments in other frontiers of AI including advances in computer vision (e.g.&nbsp;self-driving cars, medical image recognition) and speech recognition (e.g.&nbsp;Amazon Alexa, Apple Siri), but in the domain of libraries and information literacy, “AI literacy” is a crucial skill that begins with a deep understanding of large language models and the popular models currently embraced by students and researchers.</p>
<section id="inside-the-black-box-understanding-llm-input-and-output" class="level3">
<h3 class="anchored" data-anchor-id="inside-the-black-box-understanding-llm-input-and-output">Inside the Black Box: Understanding LLM Input and Output</h3>
<p>Every time you use an AI chatbot like ChatGPT, you’re participating in a process that begins with your prompt and ends with a generated response. But what happens in between?</p>
<p>This process can be broken down into three steps: <strong>input</strong>, <strong>model</strong>, and <strong>output</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/llms/chatbot-in-out.png" class="img-fluid figure-img"></p>
<figcaption>chatbot-in-out</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Components</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="./images/llms/chatbot-in.png" class="img-fluid" alt="chatbot-in"></td>
<td><strong>Input</strong>: The input is what you provide to the LLM, but it’s more than simple text limited by traditional lexical matching. Modern LLMs use Natural Language Processing (NLP) to understand the meaning and intent behind your query, going beyond simple keyword matching. To get the best results, you need to use effective prompt engineering practices. This involves carefully crafting your query with clear instructions, context, and constraints to guide the model’s output toward your desired goal. The quality of the input will influence the quality of the output.</td>
</tr>
<tr class="even">
<td><img src="./images/llms/chatbot-LLM.png" class="img-fluid" alt="chatbot-LLM"></td>
<td><strong>LLM (The Brain)</strong>: The central component here is the LLM, which acts as the “brain” of the operation. This is where the core of the AI technology resides. The LLM’s capabilities are a direct result of its training, a process where it learns patterns, relationships, and knowledge from a massive dataset. The volume of data required is immense, often consisting of trillions of words scraped from a wide variety of sources, including websites, books, and academic papers. This training phase is computationally intensive and is what allows the model to generate coherent and contextually relevant text.</td>
</tr>
<tr class="odd">
<td><img src="./images/llms/chatbot-out.png" class="img-fluid" alt="chatbot-out"></td>
<td><strong>Output</strong>: The output is the response generated by the LLM. The quality and reliability of this output are ultimately determined by the data the model was trained on. Understanding the model’s training data is crucial for determining if you can trust the output. If the training data is biased, incomplete, or contains inaccuracies, the model may generate false or nonsensical information, a phenomenon known as a hallucination. Therefore, evaluating the output involves not only checking for factual accuracy but also considering the potential for bias and the model’s limitations.</td>
</tr>
</tbody>
</table>
</section>
<section id="understanding-what-llms-know-and-what-they-dont" class="level3">
<h3 class="anchored" data-anchor-id="understanding-what-llms-know-and-what-they-dont">Understanding What LLMs Know… and What They Don’t</h3>
<p>To evaluate the output of a large language model, it’s essential to understand what data the model was trained on. For this, a powerful principle applies: <strong>“the data is the model.”</strong></p>
<p>Most foundational LLMs are trained on massive collections of publicly available web content - things like Wikipedia, Reddit, open-access articles, and code repositories. However, they largely exclude the significant body of knowledge contained in paywalled academic databases, dynamically generated web pages, and freely-accessible databases that aren’t easily crawlable.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/llms/data-is-the-model.png" class="img-fluid figure-img"></p>
<figcaption>data-is-the-model</figcaption>
</figure>
</div>
<p>Furthermore, a good deal of the most granular, timely, or academically significant data - local demographic statistics, scientific datasets, legal records, archival government data, and even historical real estate trends - lives in what we call the deep web. While technically available online, this information often requires interaction with forms, lives inside JavaScript-heavy interfaces, or is structured in ways that automated crawlers (and thus LLM training pipelines) struggle to access. If a search engine did not index it, an LLM likely did not train on it.</p>
<p>As a result, when you ask an LLM a question, you’re interacting with a system that has learned from a specific and limited subset of the web - not the full breadth of human knowledge. That’s why LLMs sometimes hallucinate or fail to answer questions that rely on specialized or hard-to-reach information. They simply haven’t seen it.</p>
<p>Large Language Models are trained on vast collections of publicly available data, giving them a broad foundational knowledge that often aligns well with the needs of undergraduate students and general education.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/llms/llm-educational-resources.png" class="img-fluid figure-img"></p>
<figcaption>llm-educational-resources</figcaption>
</figure>
</div>
<p>While this accessibility makes LLMs appealing as educational tools, their use in academic settings is still a topic of debate. Within the classroom, scholars and instructors continue to question how these tools will affect teaching, learning, and the development of critical thinking. As tools of research, LLMs need to be treated with caution.</p>
<p>It’s imporant to recognize the limitation of LLMs in conducting research. LLMs can be useful tools for brainstorming, summarizing, explanation and exploration - but they are not replacements for scholarly databases, specialized research tools, or the expertise of librarians. Valuable information remains in both library databases and the deep web - and navigating that terrain still requires human guidance and domain-specific resources.</p>
</section>
<section id="the-dominant-large-language-models" class="level3">
<h3 class="anchored" data-anchor-id="the-dominant-large-language-models">The Dominant Large Language Models</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/llms/llm-logos.jpg" class="img-fluid figure-img"></p>
<figcaption>llm-logos</figcaption>
</figure>
</div>
<p>In today’s AI landscape, OpenAI’s ChatGPT, Google’s Gemini, and Anthropic’s Claude currently stand as the three dominant Large Language Models available for public use.</p>
<p>They are all highly capable, general-purpose models that have been trained to understand and generate human-like text, allowing them to excel at a wide range of information tasks.</p>
<p><strong>Note that LLM powered chatbots are all commercial products that operate under a business model. While commercial LLMs provide a “free” tier of usage, they also offer different tiers of service and are ultimately not free for full usage of all AI tools, features and applications.</strong></p>
<p>At Baruch College, Microsoft Copilot is the preferred AI chatbot. Based upon OpenAI’s GPT-4 models, Microsoft Copilot is an AI assistant built into Microsoft 365 applications like Word and Excel. Similar to popular AI-powered chatbots like ChatGPT and Google Gemini, Copilot maintains a Large Lange Model (LLM) powered chat feature that enables it to summarize information and answer questions,</p>
<p>Data privacy remains a significant concern for the use of many AI tools. As such, Microsoft Copilot is the default generative AI tool at Baruch Colllege because all data submitted stays within the secure CUNY environment and is not shared or used to train external models.</p>
<hr>
</section>
</section>
<section id="retrieval-augmented-generation-rag" class="level2">
<h2 class="anchored" data-anchor-id="retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)</h2>
<hr>
</section>
<section id="ai-search" class="level2">
<h2 class="anchored" data-anchor-id="ai-search">AI Search</h2>
<section id="ai-assisted-research" class="level3">
<h3 class="anchored" data-anchor-id="ai-assisted-research">AI Assisted Research</h3>
<p>AI tools powered by Large Language Models are reshaping research by moving beyond simple keyword matching. These AI search tools now interpret the meaning behind your questions, analyze large volumes of content, and deliver clear, summarized insights. As AI continues to advance quickly, it will likely transform how we search for, engage with, and understand information.</p>
</section>
<section id="smarter-searching-use-ai-to-expand-your-keywords-and-enhance-your-search" class="level3">
<h3 class="anchored" data-anchor-id="smarter-searching-use-ai-to-expand-your-keywords-and-enhance-your-search">Smarter Searching: Use AI to Expand Your Keywords and Enhance Your Search</h3>
<p><img src="./images/ai-search/ai-assistants-logos.jpg" alt="AI Assistants Logos" class="img-md"></p>
<p>Traditional search, like a library catalog, finds resources by lexical matching - it directly matches your search terms with keywords in the resource’s metadata, such as its title or author.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/ai-search/keyword-matching-1.png" class="img-fluid figure-img"></p>
<figcaption>keyword-matching-1</figcaption>
</figure>
</div>
<p>A drawback of lexical matching is you can unknowingly miss potential resources unless you exhaustively search all relevant keywords:</p>
<p><img src="./images/ai-search/keyword-unmatching-2.png" class="img-fluid" alt="keyword-unmatching-2"> <img src="./images/ai-search/open-ai-keywords.jpg" class="img-fluid" alt="chat-gpt-keywords"> <img src="./images/ai-search/LLM-keywords.png" class="img-fluid" alt="LLM-keywords"></p>
<p><img src="./images/ai-search/ai-assistants-logos.jpg" class="img-fluid" alt="ai-assistants-logos"> <img src="./images/ai-search/ai-search-assistants.jpg" class="img-fluid" alt="ai-search-assistants"> <img src="./images/ai-search/ai-search-in-databases.png" class="img-fluid" alt="ai-search-in-databases"> <img src="./images/ai-search/chat-gpt-deep-research-limits.jpg" class="img-fluid" alt="chat-gpt-deep-research-limits"> <img src="./images/ai-search/deep-research-q-and-plan.png" class="img-fluid" alt="deep-research-q-and-plan"> <img src="./images/ai-search/deep-research-report.jpg" class="img-fluid" alt="deep-research-report"> <img src="./images/ai-search/deep-research-websites.png" class="img-fluid" alt="deep-research-websites"> <img src="./images/ai-search/gemini-deep-research.jpg" class="img-fluid" alt="gemini-deep-research"></p>
<p><img src="./images/ai-search/ny-times-site.jpg" class="img-fluid" alt="ny-times-site"> <img src="./images/ai-search/site-syntax-build-search-string.jpg" class="img-fluid" alt="site-syntax-build-search-string"> <img src="./images/ai-search/tabs-open-1.png" class="img-fluid" alt="tabs-open-1"> <img src="./images/ai-search/too-many-tabs.png" class="img-fluid" alt="too-many-tabs"></p>
<hr>
</section>
</section>
<section id="glossary" class="level2">
<h2 class="anchored" data-anchor-id="glossary">Glossary</h2>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>